{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from time import time\n",
    "from collections import Counter\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "# PATH_CSV = '../data/train.csv'\n",
    "# PATH_CSV = '../data/train_med.csv'\n",
    "PATH_CSV = '../data/test.csv'\n",
    "mode = os.path.splitext(os.path.basename(PATH_CSV))[0]\n",
    "print mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145232, 1932)\n",
      "CPU times: user 42.4 s, sys: 10.6 s, total: 53 s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dateparser = lambda x: pd.to_datetime(x, format='%d%b%y:%H:%M:%S', coerce=True)\n",
    "\n",
    "date_cols = ['VAR_0073', 'VAR_0075', 'VAR_0204', 'VAR_0217',\n",
    "             'VAR_0156', 'VAR_0157', 'VAR_0158', 'VAR_0159', \n",
    "             'VAR_0166', 'VAR_0167', 'VAR_0168', 'VAR_0169', \n",
    "             'VAR_0176', 'VAR_0177', 'VAR_0178', 'VAR_0179']\n",
    "\n",
    "df = pd.read_csv(PATH_CSV, parse_dates=date_cols, date_parser=dateparser,\n",
    "                      index_col='ID', engine='c')\n",
    "\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145232, 1932)\n"
     ]
    }
   ],
   "source": [
    "# Drop useless rows\n",
    "if mode == 'train':\n",
    "    df.dropna(subset=['VAR_0008'], axis=0, inplace=True)\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145232, 1888)\n"
     ]
    }
   ],
   "source": [
    "# Drop useless columns\n",
    "useless_col_path = '../saved/useless_cols.p'\n",
    "if os.path.exists(useless_col_path):\n",
    "    useless_cols = pickle.load(open(useless_col_path, 'rb'))\n",
    "else:\n",
    "    useless_cols = set()\n",
    "    for col in df.columns:\n",
    "        if len(df[col].unique()) == 1:\n",
    "            useless_cols.add(col)\n",
    "\n",
    "    pickle.dump(useless_cols, open('../saved/useless_cols.p', 'wb'))\n",
    "\n",
    "df.drop(useless_cols, axis=1, inplace=True)\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145232, 1883)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns that we may want to deal with later\n",
    "# VAR_0200 > occupation\n",
    "# VAR_0404 > another occupation?\n",
    "# VAR_0493 > city\n",
    "# VAR_0205 > continuous, but most rows are NaN\n",
    "# VAR_0214 > social sec digits or phone #? most rows are NaN\n",
    "\n",
    "handle_later_cols = [\n",
    "    'VAR_0200', 'VAR_0404', 'VAR_0493', 'VAR_0205', 'VAR_0214',\n",
    "]\n",
    "df.drop(handle_later_cols, axis=1, inplace=True)\n",
    "print df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145232, 1963)\n",
      "CPU times: user 1.39 s, sys: 12.9 s, total: 14.3 s\n",
      "Wall time: 47.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for col in date_cols:\n",
    "    dti = pd.DatetimeIndex(df[col])\n",
    "    df[col + '-year'] = dti.year\n",
    "    df[col + '-month'] = dti.month\n",
    "    df[col + '-dom'] = dti.day\n",
    "    df[col + '-dow'] = dti.dayofweek\n",
    "    df[col + '-doy'] = dti.dayofyear\n",
    "    \n",
    "    if any(df[col].isnull()):\n",
    "        df[col + '-null'] = df[col].isnull()\n",
    "        df[col + '-year'].fillna(0, inplace=True)\n",
    "        df[col + '-month'].fillna(0, inplace=True)\n",
    "        df[col + '-dom'].fillna(0, inplace=True)\n",
    "        df[col + '-dow'].fillna(0, inplace=True)\n",
    "        df[col + '-doy'].fillna(0, inplace=True)\n",
    "df.drop(date_cols, axis=1, inplace=True)\n",
    "\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoding the text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str_cols = []\n",
    "num_cols = []\n",
    "for col in df.columns:\n",
    "    if type(df[col][df[col].notnull()].iloc[0]) is str:\n",
    "        str_cols.append(col)\n",
    "    else:\n",
    "        num_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145232, 2156)\n",
      "CPU times: user 24.2 s, sys: 47.2 s, total: 1min 11s\n",
      "Wall time: 2min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# one hot encode\n",
    "\n",
    "for col in str_cols:\n",
    "#     enc = pd.get_dummies(pd.concat([train_pd[col], test_pd[col]]))\n",
    "    enc = pd.get_dummies(df[col])\n",
    "    enc.columns = ['-'.join([col, str(enc_col)]) for enc_col in enc.columns]\n",
    "    \n",
    "    df = pd.concat([df, enc[:len(df)].astype(bool)], axis=1)\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "#     test_pd = pd.concat([test_pd, enc[-len(test_pd):].astype(bool)], axis=1)\n",
    "#     test_pd.drop(col, axis=1, inplace=True)\n",
    "\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove test columns not in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2153,)\n",
      "(145232, 2151)\n",
      "CPU times: user 1.99 s, sys: 967 ms, total: 2.95 s\n",
      "Wall time: 3.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if mode == 'test':\n",
    "    train_cols = pickle.load(open('../saved/train_cols.p', 'rb'))\n",
    "    for col in df.columns:\n",
    "        if col not in train_cols:\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "    print train_cols.shape  \n",
    "elif mode == 'train':\n",
    "    pickle.dump(df.columns, open('../saved/train_cols.p', 'wb'))\n",
    "    \n",
    "print df.shape\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert empty column for any remaining columns present in train but not test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145232, 2152)\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 846 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if mode == 'test':\n",
    "    for col in set(train_cols) - set(df.columns) - {'target'}:\n",
    "        df[col] = np.zeros(len(df))\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-order columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145232, 2152)\n"
     ]
    }
   ],
   "source": [
    "df = df[train_cols.drop('target')]\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Pickle\n",
    "# df.to_pickle('../saved/train_preprocd_pd.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.97 s, sys: 2min 24s, total: 2min 28s\n",
      "Wall time: 6min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/site-packages/pandas/io/pytables.py:2558: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->['VAR_0226', 'VAR_0230', 'VAR_0232', 'VAR_0236']]\n",
      "\n",
      "  warnings.warn(ws, PerformanceWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# HDF5\n",
    "with pd.get_store('../saved/storage.h5') as store:\n",
    "    store[mode] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and save into other formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 300 ms, sys: 2.05 s, total: 2.35 s\n",
      "Wall time: 44.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "PATH_STORE = '../saved/storage.h5'\n",
    "mode = 'test'\n",
    "df = pd.read_hdf(PATH_STORE, mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.81 s, sys: 547 ms, total: 2.36 s\n",
      "Wall time: 2.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train_pd.fillna(train_pd.mean(), inplace=True)\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if mode == 'train':\n",
    "    labels = df['target']\n",
    "    df.drop(['target'], axis=1, inplace=True)\n",
    "else:\n",
    "    labels = np.zeros(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 27s, sys: 53 s, total: 24min 20s\n",
      "Wall time: 26min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "PATH_SAVE_LIBSVM = '/tmp/%s.libsvm' % mode\n",
    "\n",
    "from sklearn.datasets import dump_svmlight_file, load_svmlight_file\n",
    "# from svmlight_loader import dump_svmlight_file, load_svmlight_file\n",
    "\n",
    "dump_svmlight_file(X=df, y=labels,\n",
    "                  f=PATH_SAVE_LIBSVM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145232, 2152)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
