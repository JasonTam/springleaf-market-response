{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from time import time\n",
    "from collections import Counter\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    }
   ],
   "source": [
    "PATH_CSV = '../data/train.csv'\n",
    "# PATH_CSV = '../data/train_med.csv'\n",
    "# PATH_CSV = '../data/test.csv'\n",
    "mode = os.path.splitext(os.path.basename(PATH_CSV))[0]\n",
    "print mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145231, 1933)\n",
      "CPU times: user 48.4 s, sys: 10.8 s, total: 59.2 s\n",
      "Wall time: 5min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dateparser = lambda x: pd.to_datetime(x, format='%d%b%y:%H:%M:%S', coerce=True)\n",
    "\n",
    "date_cols = ['VAR_0073', 'VAR_0075', 'VAR_0204', 'VAR_0217',\n",
    "             'VAR_0156', 'VAR_0157', 'VAR_0158', 'VAR_0159', \n",
    "             'VAR_0166', 'VAR_0167', 'VAR_0168', 'VAR_0169', \n",
    "             'VAR_0176', 'VAR_0177', 'VAR_0178', 'VAR_0179']\n",
    "\n",
    "df = pd.read_csv(PATH_CSV, parse_dates=date_cols, date_parser=dateparser,\n",
    "                      index_col='ID', engine='c')\n",
    "\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145175, 1933)\n"
     ]
    }
   ],
   "source": [
    "# Drop useless rows\n",
    "if mode == 'train':\n",
    "    df.dropna(subset=['VAR_0008'], axis=0, inplace=True)\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145175, 1889)\n"
     ]
    }
   ],
   "source": [
    "# Drop useless columns\n",
    "useless_col_path = '../saved/useless_cols.p'\n",
    "if os.path.exists(useless_col_path):\n",
    "    useless_cols = pickle.load(open(useless_col_path, 'rb'))\n",
    "else:\n",
    "    useless_cols = set()\n",
    "    for col in df.columns:\n",
    "        if len(df[col].unique()) == 1:\n",
    "            useless_cols.add(col)\n",
    "\n",
    "    pickle.dump(useless_cols, open('../saved/useless_cols.p', 'wb'))\n",
    "\n",
    "df.drop(useless_cols, axis=1, inplace=True)\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145175, 1884)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns that we may want to deal with later\n",
    "# VAR_0200 > city\n",
    "# VAR_0404 > another occupation?\n",
    "# VAR_0493 > occupation\n",
    "# VAR_0205 > continuous, but most rows are NaN\n",
    "# VAR_0214 > social sec digits or phone #? most rows are NaN\n",
    "\n",
    "handle_later_cols = [\n",
    "    'VAR_0200', 'VAR_0404', 'VAR_0493', 'VAR_0205', 'VAR_0214',\n",
    "]\n",
    "df.drop(handle_later_cols, axis=1, inplace=True)\n",
    "print df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform date columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145175, 1961)\n",
      "CPU times: user 1.08 s, sys: 907 ms, total: 1.99 s\n",
      "Wall time: 2.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for col in date_cols:\n",
    "    dti = pd.DatetimeIndex(df[col])\n",
    "    df[col + '-year'] = dti.year\n",
    "    df[col + '-month'] = dti.month\n",
    "    df[col + '-dom'] = dti.day\n",
    "    df[col + '-dow'] = dti.dayofweek\n",
    "    df[col + '-doy'] = dti.dayofyear\n",
    "    \n",
    "    if any(df[col].isnull()):\n",
    "        df[col + '-null'] = df[col].isnull()\n",
    "        df[col + '-year'].fillna(0, inplace=True)\n",
    "        df[col + '-month'].fillna(0, inplace=True)\n",
    "        df[col + '-dom'].fillna(0, inplace=True)\n",
    "        df[col + '-dow'].fillna(0, inplace=True)\n",
    "        df[col + '-doy'].fillna(0, inplace=True)\n",
    "df.drop(date_cols, axis=1, inplace=True)\n",
    "\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoding the text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "str_cols = []\n",
    "num_cols = []\n",
    "for col in df.columns:\n",
    "    if type(df[col][df[col].notnull()].iloc[0]) is str:\n",
    "        str_cols.append(col)\n",
    "    else:\n",
    "        num_cols.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145175, 2153)\n",
      "CPU times: user 24 s, sys: 59.4 s, total: 1min 23s\n",
      "Wall time: 3min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# one hot encode\n",
    "\n",
    "for col in str_cols:\n",
    "#     enc = pd.get_dummies(pd.concat([train_pd[col], test_pd[col]]))\n",
    "    enc = pd.get_dummies(df[col])\n",
    "    enc.columns = ['-'.join([col, str(enc_col)]) for enc_col in enc.columns]\n",
    "    \n",
    "    df = pd.concat([df, enc[:len(df)].astype(bool)], axis=1)\n",
    "    df.drop(col, axis=1, inplace=True)\n",
    "#     test_pd = pd.concat([test_pd, enc[-len(test_pd):].astype(bool)], axis=1)\n",
    "#     test_pd.drop(col, axis=1, inplace=True)\n",
    "\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert boolean objects to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145175, 2153)\n"
     ]
    }
   ],
   "source": [
    "g = df.columns.to_series().groupby(df.dtypes).groups\n",
    "if np.dtype('O') in g.keys():\n",
    "    obj_cols = g[np.dtype('O')]\n",
    "    for col in  obj_cols:\n",
    "        df[col] = df[col].astype(int)\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove test columns not in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145175, 2153)\n",
      "CPU times: user 3.33 ms, sys: 60 ms, total: 63.3 ms\n",
      "Wall time: 1.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if mode == 'test':\n",
    "    train_cols = pickle.load(open('../saved/train_cols.p', 'rb'))\n",
    "    for col in df.columns:\n",
    "        if col not in train_cols:\n",
    "            df.drop(col, axis=1, inplace=True)\n",
    "    print train_cols.shape  \n",
    "elif mode == 'train':\n",
    "    pickle.dump(df.columns, open('../saved/train_cols.p', 'wb'))\n",
    "    \n",
    "print df.shape\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert empty column for any remaining columns present in train but not test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145175, 2153)\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 62 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if mode == 'test':\n",
    "    for col in set(train_cols) - set(df.columns) - {'target'}:\n",
    "        df[col] = np.zeros(len(df))\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-order columns to be the same order as train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145175, 2153)\n"
     ]
    }
   ],
   "source": [
    "if mode == 'test':\n",
    "    df = df[train_cols.drop('target')]\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# Pickle\n",
    "# df.to_pickle('../saved/train_preprocd_pd.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.65 s, sys: 2min 34s, total: 2min 41s\n",
      "Wall time: 7min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# HDF5\n",
    "with pd.get_store('../saved/storage.h5') as store:\n",
    "    store.put(mode, df, format='table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and save into other formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 300 ms, sys: 2.05 s, total: 2.35 s\n",
      "Wall time: 44.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "PATH_STORE = '../saved/storage.h5'\n",
    "mode = 'test'\n",
    "df = pd.read_hdf(PATH_STORE, mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.81 s, sys: 547 ms, total: 2.36 s\n",
      "Wall time: 2.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train_pd.fillna(train_pd.mean(), inplace=True)\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if mode == 'train':\n",
    "    labels = df['target']\n",
    "    df.drop(['target'], axis=1, inplace=True)\n",
    "else:\n",
    "    labels = np.zeros(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 27s, sys: 53 s, total: 24min 20s\n",
      "Wall time: 26min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "PATH_SAVE_LIBSVM = '/tmp/%s.libsvm' % mode\n",
    "\n",
    "from sklearn.datasets import dump_svmlight_file, load_svmlight_file\n",
    "# from svmlight_loader import dump_svmlight_file, load_svmlight_file\n",
    "\n",
    "dump_svmlight_file(X=df, y=labels,\n",
    "                  f=PATH_SAVE_LIBSVM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchspace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Processing Numerical Columns\n",
    "\n",
    "Some numerical columns contain values that obviously represent some sort of categorical flag (ie. 99998). We need to detect which columns contain these flag values, what the values are, and finally, strip the values out to separate one-hot encoded columns. \n",
    "\n",
    "### Detection\n",
    "\n",
    "Counter -> find values that occur many (say n/100) times. Check that the most significant digit is 9... just because that's how it seems SpringLeaf has encoded the data.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
